{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipkmrMKH94me"
   },
   "source": [
    "# GhostNet Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\digit-recognition\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\anaconda3\\envs\\digit-recognition\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\digit-recognition\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\envs\\digit-recognition\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\digit-recognition\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = mnist.load_data()\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=-1) / 255.0\n",
    "X_test = np.expand_dims(X_test, axis=-1) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GhostNet building blocks\n",
    "def ghost_module(x, out_channels, ratio=2, dw_kernel_size=3, s=1):\n",
    "    init_channels = int(np.ceil(out_channels / ratio))\n",
    "    new_channels = init_channels * (ratio - 1)\n",
    "    \n",
    "    # Primary convolution\n",
    "    primary_conv = layers.Conv2D(init_channels, kernel_size=1, strides=s, padding='same')(x)\n",
    "    primary_conv = layers.BatchNormalization()(primary_conv)\n",
    "    primary_conv = layers.ReLU()(primary_conv)\n",
    "    \n",
    "    # Depthwise convolution\n",
    "    depthwise_conv = layers.DepthwiseConv2D(kernel_size=dw_kernel_size, strides=s, padding='same')(primary_conv)\n",
    "    depthwise_conv = layers.BatchNormalization()(depthwise_conv)\n",
    "    depthwise_conv = layers.ReLU()(depthwise_conv)\n",
    "    \n",
    "    # Ghost feature maps (pointwise conv to generate extra features)\n",
    "    ghost_conv = layers.Conv2D(new_channels, kernel_size=1, strides=1, padding='same')(depthwise_conv)\n",
    "    ghost_conv = layers.BatchNormalization()(ghost_conv)\n",
    "    ghost_conv = layers.ReLU()(ghost_conv)\n",
    "    \n",
    "    # Concatenate primary and ghost\n",
    "    out = layers.Concatenate()([primary_conv, ghost_conv])\n",
    "    \n",
    "    return out\n",
    "\n",
    "# Building a simple GhostNet-based model for MNIST\n",
    "def build_ghostnet(input_shape=(28, 28, 1), num_classes=10):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Initial stem layer\n",
    "    x = layers.Conv2D(16, kernel_size=3, strides=1, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    \n",
    "    # First ghost block\n",
    "    x = ghost_module(x, out_channels=32)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    # Second ghost block\n",
    "    x = ghost_module(x, out_channels=64)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    # Third ghost block\n",
    "    x = ghost_module(x, out_channels=128)\n",
    "    \n",
    "    # Global average pooling and dense layer for classification\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)            (None, 28, 28, 16)   160         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_269 (Batch  (None, 28, 28, 16)  64          ['conv2d_266[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_269[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)            (None, 28, 28, 16)   272         ['re_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_270 (Batch  (None, 28, 28, 16)  64          ['conv2d_267[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_198 (Depthwis  (None, 28, 28, 16)  160         ['re_lu_21[0][0]']               \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_271 (Batch  (None, 28, 28, 16)  64          ['depthwise_conv2d_198[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)            (None, 28, 28, 16)   272         ['re_lu_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_272 (Batch  (None, 28, 28, 16)  64          ['conv2d_268[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_102 (Concatenate)  (None, 28, 28, 32)   0           ['re_lu_21[0][0]',               \n",
      "                                                                  're_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 32)  0           ['concatenate_102[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)            (None, 14, 14, 32)   1056        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_273 (Batch  (None, 14, 14, 32)  128         ['conv2d_269[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 14, 14, 32)   0           ['batch_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_199 (Depthwis  (None, 14, 14, 32)  320         ['re_lu_24[0][0]']               \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_274 (Batch  (None, 14, 14, 32)  128         ['depthwise_conv2d_199[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 14, 14, 32)   0           ['batch_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)            (None, 14, 14, 32)   1056        ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_275 (Batch  (None, 14, 14, 32)  128         ['conv2d_270[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 14, 14, 32)   0           ['batch_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_103 (Concatenate)  (None, 14, 14, 64)   0           ['re_lu_24[0][0]',               \n",
      "                                                                  're_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 64)    0           ['concatenate_103[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)            (None, 7, 7, 64)     4160        ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_276 (Batch  (None, 7, 7, 64)    256         ['conv2d_271[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 7, 7, 64)     0           ['batch_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_200 (Depthwis  (None, 7, 7, 64)    640         ['re_lu_27[0][0]']               \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_277 (Batch  (None, 7, 7, 64)    256         ['depthwise_conv2d_200[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 7, 7, 64)     0           ['batch_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)            (None, 7, 7, 64)     4160        ['re_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_278 (Batch  (None, 7, 7, 64)    256         ['conv2d_272[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 7, 7, 64)     0           ['batch_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 7, 7, 128)    0           ['re_lu_27[0][0]',               \n",
      "                                                                  're_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_53 (G  (None, 128)         0           ['concatenate_104[0][0]']        \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           1290        ['global_average_pooling2d_53[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,954\n",
      "Trainable params: 14,250\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)            (None, 28, 28, 16)   160         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_269 (Batch  (None, 28, 28, 16)  64          ['conv2d_266[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_269[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)            (None, 28, 28, 16)   272         ['re_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_270 (Batch  (None, 28, 28, 16)  64          ['conv2d_267[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_198 (Depthwis  (None, 28, 28, 16)  160         ['re_lu_21[0][0]']               \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_271 (Batch  (None, 28, 28, 16)  64          ['depthwise_conv2d_198[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)            (None, 28, 28, 16)   272         ['re_lu_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_272 (Batch  (None, 28, 28, 16)  64          ['conv2d_268[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_102 (Concatenate)  (None, 28, 28, 32)   0           ['re_lu_21[0][0]',               \n",
      "                                                                  're_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 32)  0           ['concatenate_102[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)            (None, 14, 14, 32)   1056        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_273 (Batch  (None, 14, 14, 32)  128         ['conv2d_269[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 14, 14, 32)   0           ['batch_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_199 (Depthwis  (None, 14, 14, 32)  320         ['re_lu_24[0][0]']               \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_274 (Batch  (None, 14, 14, 32)  128         ['depthwise_conv2d_199[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 14, 14, 32)   0           ['batch_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)            (None, 14, 14, 32)   1056        ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_275 (Batch  (None, 14, 14, 32)  128         ['conv2d_270[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 14, 14, 32)   0           ['batch_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_103 (Concatenate)  (None, 14, 14, 64)   0           ['re_lu_24[0][0]',               \n",
      "                                                                  're_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 64)    0           ['concatenate_103[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)            (None, 7, 7, 64)     4160        ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_276 (Batch  (None, 7, 7, 64)    256         ['conv2d_271[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 7, 7, 64)     0           ['batch_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_200 (Depthwis  (None, 7, 7, 64)    640         ['re_lu_27[0][0]']               \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_277 (Batch  (None, 7, 7, 64)    256         ['depthwise_conv2d_200[0][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 7, 7, 64)     0           ['batch_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)            (None, 7, 7, 64)     4160        ['re_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_278 (Batch  (None, 7, 7, 64)    256         ['conv2d_272[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 7, 7, 64)     0           ['batch_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 7, 7, 128)    0           ['re_lu_27[0][0]',               \n",
      "                                                                  're_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_53 (G  (None, 128)         0           ['concatenate_104[0][0]']        \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           1290        ['global_average_pooling2d_53[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,954\n",
      "Trainable params: 14,250\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the GhostNet model\n",
    "model = build_ghostnet()\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 76s 39ms/step - loss: 0.3469 - accuracy: 0.9178 - val_loss: 0.1437 - val_accuracy: 0.9573\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 63s 33ms/step - loss: 0.0828 - accuracy: 0.9758 - val_loss: 0.1064 - val_accuracy: 0.9673\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 88s 47ms/step - loss: 0.0582 - accuracy: 0.9825 - val_loss: 0.0778 - val_accuracy: 0.9753\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 117s 62ms/step - loss: 0.0489 - accuracy: 0.9857 - val_loss: 0.0622 - val_accuracy: 0.9793\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.0408 - val_accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0378 - accuracy: 0.9883 - val_loss: 0.0395 - val_accuracy: 0.9881\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0339 - accuracy: 0.9892 - val_loss: 0.0532 - val_accuracy: 0.9823\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 0.0606 - val_accuracy: 0.9795\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0495 - val_accuracy: 0.9842\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.0451 - val_accuracy: 0.9852\n",
      "Total time: 754.72 seconds\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0451 - accuracy: 0.9852\n",
      "Test accuracy: 0.9851999878883362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on MNIST\n",
    "start_original_time = time.time()\n",
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10) # Epochs 3 aja udah gacor, tapi secara waktu sama aja wokawo, 3x lipat per-epoch\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_original_time \n",
    "print(f\"Total time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0451 - accuracy: 0.9852\n",
      "Test accuracy: 0.9851999878883362\n"
     ]
    }
   ],
   "source": [
    "# Evaluate original model\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZkMQdy5i-Ll5",
    "outputId": "3e24a048-7479-429d-d754-69f0f98e088b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 380.66 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "original_model = model\n",
    "\n",
    "# model_save_path = 'cnn_model.h5'\n",
    "model_save_path = 'model2.keras'\n",
    "original_model.save(model_save_path)\n",
    "\n",
    "# Get the size of the model in bytes\n",
    "model_size = os.path.getsize(model_save_path)\n",
    "print(f\"Model size: {model_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRmtfg0PB1sH"
   },
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZe-b1_QCCJb",
    "outputId": "0861cd33-d760-4947-fbe9-582ded7ba135"
   },
   "outputs": [],
   "source": [
    "! pip install -q tensorflow-model-optimization\n",
    "import tensorflow_model_optimization as tfmot  # TensorFlow Model Optimization toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkI4XhcKB2y1",
    "outputId": "a70acfba-95b8-4f0f-a87d-96d8fcc4b74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_259  (None, 28, 28, 16)  306         ['input_2[0][0]']                \n",
      "  (PruneLowMagnitude)                                                                             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 28, 28, 16)  65          ['prune_low_magnitude_conv2d_259[\n",
      " alization_259 (PruneLowMagnitu                                  0][0]']                          \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_10 (  (None, 28, 28, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_259[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_260  (None, 28, 28, 16)  530         ['prune_low_magnitude_re_lu_10[0]\n",
      "  (PruneLowMagnitude)                                            [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 28, 28, 16)  65          ['prune_low_magnitude_conv2d_260[\n",
      " alization_260 (PruneLowMagnitu                                  0][0]']                          \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_11 (  (None, 28, 28, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_260[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_depthwise_  (None, 28, 28, 16)  161         ['prune_low_magnitude_re_lu_11[0]\n",
      " conv2d_195 (PruneLowMagnitude)                                  [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 28, 28, 16)  65          ['prune_low_magnitude_depthwise_c\n",
      " alization_261 (PruneLowMagnitu                                  onv2d_195[0][0]']                \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_12 (  (None, 28, 28, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_261[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_261  (None, 28, 28, 16)  530         ['prune_low_magnitude_re_lu_12[0]\n",
      "  (PruneLowMagnitude)                                            [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 28, 28, 16)  65          ['prune_low_magnitude_conv2d_261[\n",
      " alization_262 (PruneLowMagnitu                                  0][0]']                          \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_13 (  (None, 28, 28, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_262[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_concatenat  (None, 28, 28, 32)  1           ['prune_low_magnitude_re_lu_11[0]\n",
      " e_99 (PruneLowMagnitude)                                        [0]',                            \n",
      "                                                                  'prune_low_magnitude_re_lu_13[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_max_poolin  (None, 14, 14, 32)  1           ['prune_low_magnitude_concatenate\n",
      " g2d_2 (PruneLowMagnitude)                                       _99[0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_262  (None, 14, 14, 32)  2082        ['prune_low_magnitude_max_pooling\n",
      "  (PruneLowMagnitude)                                            2d_2[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 14, 14, 32)  129         ['prune_low_magnitude_conv2d_262[\n",
      " alization_263 (PruneLowMagnitu                                  0][0]']                          \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_14 (  (None, 14, 14, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_263[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_depthwise_  (None, 14, 14, 32)  321         ['prune_low_magnitude_re_lu_14[0]\n",
      " conv2d_196 (PruneLowMagnitude)                                  [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 14, 14, 32)  129         ['prune_low_magnitude_depthwise_c\n",
      " alization_264 (PruneLowMagnitu                                  onv2d_196[0][0]']                \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_15 (  (None, 14, 14, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_264[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_263  (None, 14, 14, 32)  2082        ['prune_low_magnitude_re_lu_15[0]\n",
      "  (PruneLowMagnitude)                                            [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 14, 14, 32)  129         ['prune_low_magnitude_conv2d_263[\n",
      " alization_265 (PruneLowMagnitu                                  0][0]']                          \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_16 (  (None, 14, 14, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_265[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_concatenat  (None, 14, 14, 64)  1           ['prune_low_magnitude_re_lu_14[0]\n",
      " e_100 (PruneLowMagnitude)                                       [0]',                            \n",
      "                                                                  'prune_low_magnitude_re_lu_16[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_max_poolin  (None, 7, 7, 64)    1           ['prune_low_magnitude_concatenate\n",
      " g2d_3 (PruneLowMagnitude)                                       _100[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_264  (None, 7, 7, 64)    8258        ['prune_low_magnitude_max_pooling\n",
      "  (PruneLowMagnitude)                                            2d_3[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 7, 7, 64)    257         ['prune_low_magnitude_conv2d_264[\n",
      " alization_266 (PruneLowMagnitu                                  0][0]']                          \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_17 (  (None, 7, 7, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_266[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_depthwise_  (None, 7, 7, 64)    641         ['prune_low_magnitude_re_lu_17[0]\n",
      " conv2d_197 (PruneLowMagnitude)                                  [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 7, 7, 64)    257         ['prune_low_magnitude_depthwise_c\n",
      " alization_267 (PruneLowMagnitu                                  onv2d_197[0][0]']                \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_18 (  (None, 7, 7, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_267[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_265  (None, 7, 7, 64)    8258        ['prune_low_magnitude_re_lu_18[0]\n",
      "  (PruneLowMagnitude)                                            [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 7, 7, 64)    257         ['prune_low_magnitude_conv2d_265[\n",
      " alization_268 (PruneLowMagnitu                                  0][0]']                          \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_19 (  (None, 7, 7, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " PruneLowMagnitude)                                              lization_268[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_concatenat  (None, 7, 7, 128)   1           ['prune_low_magnitude_re_lu_17[0]\n",
      " e_101 (PruneLowMagnitude)                                       [0]',                            \n",
      "                                                                  'prune_low_magnitude_re_lu_19[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_global_ave  (None, 128)         1           ['prune_low_magnitude_concatenate\n",
      " rage_pooling2d_52 (PruneLowMag                                  _101[0][0]']                     \n",
      " nitude)                                                                                          \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_1 (P  (None, 10)          2572        ['prune_low_magnitude_global_aver\n",
      " runeLowMagnitude)                                               age_pooling2d_52[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,175\n",
      "Trainable params: 14,250\n",
      "Non-trainable params: 12,925\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "pruning_params = {\n",
    "      # 'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
    "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.1, begin_step=0, frequency=100)\n",
    "  }\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep()\n",
    "]\n",
    "\n",
    "pruned_model = prune_low_magnitude(original_model, **pruning_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "pruned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2jei0CHB97E",
    "outputId": "a3dce854-c907-40ed-f795-edf400a42c8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 68s 39ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0562 - val_accuracy: 0.9818\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 58s 38ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0427 - val_accuracy: 0.9853\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 56s 37ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.0312 - val_accuracy: 0.9908\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 56s 37ms/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.0278 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.0383 - val_accuracy: 0.9886\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0370 - val_accuracy: 0.9878\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 55s 36ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.0389 - val_accuracy: 0.9866\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 57s 38ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0292 - val_accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.0297 - val_accuracy: 0.9914\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 57s 38ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0327 - val_accuracy: 0.9890\n",
      "Total time: 571.26 seconds\n"
     ]
    }
   ],
   "source": [
    "start_pruning_time = time.time()\n",
    "pruned_model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  # epochs=10,\n",
    "  epochs=3,\n",
    "  validation_split=0.2,\n",
    "  callbacks=callbacks)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_pruning_time \n",
    "print(f\"Total time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 12ms/step - loss: 0.0394 - accuracy: 0.9869\n",
      "Test accuracy: 0.9868999719619751\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "pruned_test_loss, pruned_test_acc = pruned_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test accuracy: {pruned_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWr2HCqIB39h",
    "outputId": "2428777e-64a1-4d3e-cff1-983910ce4bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size after pruning: 516.24 KB\n"
     ]
    }
   ],
   "source": [
    "model_save_path = 'cnn_pruned_model2.keras'\n",
    "pruned_model.save(model_save_path)\n",
    "\n",
    "# Get the size of the model in bytes\n",
    "model_size = os.path.getsize(model_save_path)\n",
    "print(f\"Model size after pruning: {model_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uf6Os_KfMQ9y",
    "outputId": "7b94b1ef-7a66-4b76-8304-d47883a667b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmp6njuwjzo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmp6njuwjzo\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size after pruning + convert to tf lite: 62.91 KB\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "model_save_path = 'pruned_model2.tflite'\n",
    "with open('pruned_model2.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "model_size = os.path.getsize(model_save_path)\n",
    "print(f\"Model size after pruning + convert to tf lite: {model_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjpIwk9-B3GS"
   },
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "6UT9TGGTIcNa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmprewbgc9r\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmprewbgc9r\\assets\n"
     ]
    }
   ],
   "source": [
    "# Strip the pruning wrappers to finalize the pruned model\n",
    "final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "# Convert to TensorFlow Lite model with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "\n",
    "# Set quantization parameters\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Default optimization includes quantization\n",
    "\n",
    "# Optionally, if you have representative data, you can enable full integer quantization:\n",
    "# Provide a representative dataset for better accuracy in quantization\n",
    "def representative_dataset():\n",
    "    for data in X_test.take(100):  # use a small sample of your data <<< what if we change this to 1000? to all data? 70rb? how?\n",
    "        yield [tf.dtypes.cast(data, tf.float32)] # can we change this to integer?\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_types = [tf.float16]  # This can be int8 as well, hm... << nope, error\n",
    "\n",
    "# Convert the model\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized model to a file\n",
    "with open('quantized_pruned_model2.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "# To load and use the TFLite model later:\n",
    "interpreter = tf.lite.Interpreter(model_path='quantized_pruned_model2.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)            (None, 28, 28, 16)   160         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_259 (Batch  (None, 28, 28, 16)  64          ['conv2d_259[2][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_259[2][0]']\n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)            (None, 28, 28, 16)   272         ['re_lu_10[2][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_260 (Batch  (None, 28, 28, 16)  64          ['conv2d_260[2][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_260[2][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_195 (Depthwis  (None, 28, 28, 16)  160         ['re_lu_11[2][0]']               \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_261 (Batch  (None, 28, 28, 16)  64          ['depthwise_conv2d_195[2][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_261[2][0]']\n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)            (None, 28, 28, 16)   272         ['re_lu_12[2][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_262 (Batch  (None, 28, 28, 16)  64          ['conv2d_261[2][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 28, 28, 16)   0           ['batch_normalization_262[2][0]']\n",
      "                                                                                                  \n",
      " concatenate_99 (Concatenate)   (None, 28, 28, 32)   0           ['re_lu_11[2][0]',               \n",
      "                                                                  're_lu_13[2][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 32)  0           ['concatenate_99[2][0]']         \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)            (None, 14, 14, 32)   1056        ['max_pooling2d_2[2][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_263 (Batch  (None, 14, 14, 32)  128         ['conv2d_262[2][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 14, 14, 32)   0           ['batch_normalization_263[2][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_196 (Depthwis  (None, 14, 14, 32)  320         ['re_lu_14[2][0]']               \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_264 (Batch  (None, 14, 14, 32)  128         ['depthwise_conv2d_196[2][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 14, 14, 32)   0           ['batch_normalization_264[2][0]']\n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)            (None, 14, 14, 32)   1056        ['re_lu_15[2][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_265 (Batch  (None, 14, 14, 32)  128         ['conv2d_263[2][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 14, 14, 32)   0           ['batch_normalization_265[2][0]']\n",
      "                                                                                                  \n",
      " concatenate_100 (Concatenate)  (None, 14, 14, 64)   0           ['re_lu_14[2][0]',               \n",
      "                                                                  're_lu_16[2][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)    0           ['concatenate_100[2][0]']        \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)            (None, 7, 7, 64)     4160        ['max_pooling2d_3[2][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_266 (Batch  (None, 7, 7, 64)    256         ['conv2d_264[2][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 7, 7, 64)     0           ['batch_normalization_266[2][0]']\n",
      "                                                                                                  \n",
      " depthwise_conv2d_197 (Depthwis  (None, 7, 7, 64)    640         ['re_lu_17[2][0]']               \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_267 (Batch  (None, 7, 7, 64)    256         ['depthwise_conv2d_197[2][0]']   \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 7, 7, 64)     0           ['batch_normalization_267[2][0]']\n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)            (None, 7, 7, 64)     4160        ['re_lu_18[2][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_268 (Batch  (None, 7, 7, 64)    256         ['conv2d_265[2][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 7, 7, 64)     0           ['batch_normalization_268[2][0]']\n",
      "                                                                                                  \n",
      " concatenate_101 (Concatenate)  (None, 7, 7, 128)    0           ['re_lu_17[2][0]',               \n",
      "                                                                  're_lu_19[2][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_52 (G  (None, 128)         0           ['concatenate_101[2][0]']        \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           1290        ['global_average_pooling2d_52[2][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,954\n",
      "Trainable params: 14,250\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "WXVXOC1-Ipk7"
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXR8QECMIten",
    "outputId": "2bb0137d-b75b-475f-b23e-63725999ced5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 55s 36ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.0244 - val_accuracy: 0.9920\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.0431 - val_accuracy: 0.9882\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 56s 37ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.1375 - val_accuracy: 0.9605\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 54s 36ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0295 - val_accuracy: 0.9903\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 54s 36ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0368 - val_accuracy: 0.9896\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 55s 37ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0271 - val_accuracy: 0.9929\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 54s 36ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0546 - val_accuracy: 0.9843\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 52s 35ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0419 - val_accuracy: 0.9885\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 53s 35ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0374 - val_accuracy: 0.9893\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 53s 35ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0389 - val_accuracy: 0.9886\n",
      "Total time: 543.19 seconds\n"
     ]
    }
   ],
   "source": [
    "start_quantization_time = time.time()\n",
    "final_model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  epochs=10,\n",
    "  validation_split=0.2,\n",
    "  callbacks=callbacks)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_quantization_time \n",
    "print(f\"Total time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 10ms/step - loss: 0.0487 - accuracy: 0.9877\n",
      "Test accuracy: 0.9876999855041504\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "quantization_test_loss, quantization_test_acc = final_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test accuracy: {quantization_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zaTURCDIvgP",
    "outputId": "7683a35f-67b8-44f3-a31b-bd94c5d1d488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size after quantization: 41.38 KB\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize('quantized_pruned_model2.tflite')\n",
    "print(f\"Model size after quantization: {model_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii8OHpBm96h0"
   },
   "source": [
    "# Optimized Model with Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmX6HqMu98rB",
    "outputId": "ed225d3d-c336-4ab7-df58-f473a16bd6e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 17s 9ms/step\n",
      "Epoch 1/10\n",
      "Loss: 0.4134, Accuracy: 0.0658\n",
      "Epoch 2/10\n",
      "Loss: 0.1944, Accuracy: 0.0660\n",
      "Epoch 3/10\n",
      "Loss: 0.1538, Accuracy: 0.0659\n",
      "Epoch 4/10\n",
      "Loss: 0.1311, Accuracy: 0.0659\n",
      "Epoch 5/10\n",
      "Loss: 0.1262, Accuracy: 0.0659\n",
      "Epoch 6/10\n",
      "Loss: 0.1070, Accuracy: 0.0659\n",
      "Epoch 7/10\n",
      "Loss: 0.1170, Accuracy: 0.0659\n",
      "Epoch 8/10\n",
      "Loss: 0.0944, Accuracy: 0.0659\n",
      "Epoch 9/10\n",
      "Loss: 0.1073, Accuracy: 0.0659\n",
      "Epoch 10/10\n",
      "Loss: 0.0963, Accuracy: 0.0659\n",
      "Total time: 2204.69 seconds\n"
     ]
    }
   ],
   "source": [
    "# Custom loss function for Knowledge Distillation\n",
    "def distillation_loss(y_true, y_pred, teacher_logits, temperature=5.0, alpha=0.5):\n",
    "    student_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    distillation_loss = tf.keras.losses.KLDivergence()(\n",
    "        tf.nn.softmax(teacher_logits / temperature),\n",
    "        tf.nn.softmax(y_pred / temperature)\n",
    "    )\n",
    "    return alpha * student_loss + (1 - alpha) * distillation_loss\n",
    "\n",
    "# Train student model with teacher model's logits\n",
    "def train_student_model(student_model, teacher_model, X_train, y_train):\n",
    "    teacher_logits = teacher_model.predict(X_train)\n",
    "\n",
    "    # Custom training loop\n",
    "    start_kd_time = time.time()    \n",
    "    for epoch in range(10):\n",
    "        print(f\"Epoch {epoch + 1}/10\")\n",
    "        epoch_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        for i in range(0, len(X_train), 32):\n",
    "            X_batch = X_train[i:i+32]\n",
    "            y_batch = y_train[i:i+32]\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = student_model(X_batch, training=True)\n",
    "                loss = distillation_loss(y_batch, y_pred, teacher_logits[i:i+32])\n",
    "            grads = tape.gradient(loss, student_model.trainable_variables)\n",
    "            student_model.optimizer.apply_gradients(zip(grads, student_model.trainable_variables))\n",
    "\n",
    "            # Track loss and accuracy\n",
    "            epoch_loss += loss.numpy().sum() * len(y_batch)  # Ensure loss is a scalar\n",
    "            correct_predictions += np.sum(np.argmax(y_pred.numpy(), axis=-1) == np.argmax(y_batch, axis=-1))\n",
    "            total_predictions += len(y_batch)\n",
    "\n",
    "        average_loss = epoch_loss / total_predictions\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        print(f\"Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_kd_time \n",
    "    print(f\"Total time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Train the student model\n",
    "student_model = original_model\n",
    "train_student_model(student_model, final_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNM74FvgcpeZ",
    "outputId": "ded009ee-d7bb-4512-f295-fc1719c57940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0607 - accuracy: 0.9834\n",
      "Student Model Accuracy: 0.9833999872207642, Loss: 0.06066780909895897\n"
     ]
    }
   ],
   "source": [
    "# Evaluate student model\n",
    "student_loss, student_accuracy = student_model.evaluate(X_test, y_test)\n",
    "print(f\"Student Model Accuracy: {student_accuracy}, Loss: {student_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvNc6DjyBeIV",
    "outputId": "a7da896f-6769-4ec5-b1c8-9bd9406f5449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 380.66 KB\n"
     ]
    }
   ],
   "source": [
    "# model_save_path = 'cnn_model.h5'\n",
    "model_save_path = 'student_model2.keras'\n",
    "student_model.save(model_save_path)\n",
    "\n",
    "# Get the size of the model in bytes\n",
    "model_size = os.path.getsize(model_save_path)\n",
    "print(f\"Model size: {model_size / 1024:.2f} KB\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "digit-recognition",
   "language": "python",
   "name": "digit-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
