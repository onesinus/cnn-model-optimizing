{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# model 2"
      ],
      "metadata": {
        "id": "ipkmrMKH94me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = np.expand_dims(X_train, -1).astype(\"float32\") / 255.0\n",
        "X_test = np.expand_dims(X_test, -1).astype(\"float32\") / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Define original CNN model\n",
        "def create_original_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile and train original model\n",
        "original_model = create_original_model()\n",
        "original_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB6hrGdc8PlJ",
        "outputId": "960e1862-a144-463a-d0c6-6806ad3b8d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                102464    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121930 (476.29 KB)\n",
            "Trainable params: 121930 (476.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "original_model.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=32)\n",
        "\n",
        "# Evaluate original model\n",
        "original_loss, original_accuracy = original_model.evaluate(X_test, y_test)\n",
        "print(f\"Original Model Accuracy: {original_accuracy}, Loss: {original_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ46krPhCo2u",
        "outputId": "d0d72537-d88d-401b-dc0d-56ab5fe62534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 40s 26ms/step - loss: 0.1654 - accuracy: 0.9501 - val_loss: 0.0703 - val_accuracy: 0.9803\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 36s 24ms/step - loss: 0.0520 - accuracy: 0.9840 - val_loss: 0.0498 - val_accuracy: 0.9856\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 39s 26ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 0.0378 - val_accuracy: 0.9896\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.0454 - val_accuracy: 0.9865\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 39s 26ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0362 - val_accuracy: 0.9899\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 37s 25ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 0.0359 - val_accuracy: 0.9906\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0439 - val_accuracy: 0.9881\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 39s 26ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0585 - val_accuracy: 0.9870\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0468 - val_accuracy: 0.9894\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0530 - val_accuracy: 0.9890\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0464 - accuracy: 0.9884\n",
            "Original Model Accuracy: 0.9883999824523926, Loss: 0.046377941966056824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# model_save_path = 'cnn_model.h5'\n",
        "model_save_path = 'model2.keras'\n",
        "original_model.save(model_save_path)\n",
        "\n",
        "# Get the size of the model in bytes\n",
        "model_size = os.path.getsize(model_save_path)\n",
        "print(f\"Model size: {model_size / 1024:.2f} KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkMQdy5i-Ll5",
        "outputId": "3e24a048-7479-429d-d754-69f0f98e088b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 1465.01 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pruning"
      ],
      "metadata": {
        "id": "CRmtfg0PB1sH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot  # TensorFlow Model Optimization toolkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZe-b1_QCCJb",
        "outputId": "0861cd33-d760-4947-fbe9-582ded7ba135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/242.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tf_keras as keras"
      ],
      "metadata": {
        "id": "-Yhs6DmfCWIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "pruning_params = {\n",
        "      # 'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
        "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.1, begin_step=0, frequency=100)\n",
        "  }\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep()\n",
        "]\n",
        "\n",
        "pruned_model = prune_low_magnitude(original_model, **pruning_params)\n",
        "\n",
        "# Use smaller learning rate for fine-tuning\n",
        "opt = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "pruned_model.compile(\n",
        "  loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "pruned_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkI4XhcKB2y1",
        "outputId": "a70acfba-95b8-4f0f-a87d-96d8fcc4b74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d  (None, 26, 26, 32)        610       \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 13, 13, 32)        1         \n",
            " oling2d (PruneLowMagnitude                                      \n",
            " )                                                               \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d  (None, 11, 11, 64)        36930     \n",
            " _1 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_max_po  (None, 5, 5, 64)          1         \n",
            " oling2d_1 (PruneLowMagnitu                                      \n",
            " de)                                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_flatte  (None, 1600)              1         \n",
            " n (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_dense   (None, 64)                204866    \n",
            " (PruneLowMagnitude)                                             \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_  (None, 10)                1292      \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 243701 (951.98 KB)\n",
            "Trainable params: 121930 (476.29 KB)\n",
            "Non-trainable params: 121771 (475.70 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model.fit(\n",
        "  X_train,\n",
        "  y_train,\n",
        "  epochs=10,\n",
        "  validation_split=0.2,\n",
        "  callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2jei0CHB97E",
        "outputId": "a3dce854-c907-40ed-f795-edf400a42c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tf_keras/src/backend.py:5577: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1500/1500 [==============================] - 43s 27ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0414 - val_accuracy: 0.9912\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 39s 26ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0394 - val_accuracy: 0.9916\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0388 - val_accuracy: 0.9921\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0386 - val_accuracy: 0.9924\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0384 - val_accuracy: 0.9923\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0383 - val_accuracy: 0.9923\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 38s 26ms/step - loss: 8.8877e-04 - accuracy: 0.9998 - val_loss: 0.0384 - val_accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 39s 26ms/step - loss: 7.5191e-04 - accuracy: 0.9999 - val_loss: 0.0385 - val_accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 6.3765e-04 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9925\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 37s 25ms/step - loss: 5.4887e-04 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9927\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7a55d0895330>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = 'cnn_pruned_model.keras'\n",
        "pruned_model.save(model_save_path)\n",
        "\n",
        "# Get the size of the model in bytes\n",
        "model_size = os.path.getsize(model_save_path)\n",
        "print(f\"Model size after pruning: {model_size / 1024:.2f} KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWr2HCqIB39h",
        "outputId": "2428777e-64a1-4d3e-cff1-983910ce4bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size after pruning: 2439.63 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model to a file\n",
        "model_save_path = 'pruned_model.tflite'\n",
        "with open('pruned_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "model_size = os.path.getsize(model_save_path)\n",
        "print(f\"Model size after pruning + convert to tf lite: {model_size / 1024:.2f} KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf6Os_KfMQ9y",
        "outputId": "7b94b1ef-7a66-4b76-8304-d47883a667b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size after pruning + convert to tf lite: 479.57 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantization"
      ],
      "metadata": {
        "id": "FjpIwk9-B3GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip the pruning wrappers to finalize the pruned model\n",
        "final_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "\n",
        "# Convert to TensorFlow Lite model with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "\n",
        "# Set quantization parameters\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Default optimization includes quantization\n",
        "\n",
        "# Optionally, if you have representative data, you can enable full integer quantization:\n",
        "# Provide a representative dataset for better accuracy in quantization\n",
        "def representative_dataset():\n",
        "    for data in X_test.take(100):  # use a small sample of your data <<< what if we change this to 1000? to all data? 70rb? how?\n",
        "        yield [tf.dtypes.cast(data, tf.float32)] # can we change this to integer?\n",
        "\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_types = [tf.float16]  # This can be int8 as well, hm... << nope, error\n",
        "\n",
        "# Convert the model\n",
        "quantized_tflite_model = converter.convert()\n",
        "\n",
        "# Save the quantized model to a file\n",
        "with open('quantized_pruned_model.tflite', 'wb') as f:\n",
        "    f.write(quantized_tflite_model)\n",
        "\n",
        "# To load and use the TFLite model later:\n",
        "interpreter = tf.lite.Interpreter(model_path='quantized_pruned_model.tflite')\n",
        "interpreter.allocate_tensors()"
      ],
      "metadata": {
        "id": "6UT9TGGTIcNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.compile(\n",
        "  loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  optimizer=opt,\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "WXVXOC1-Ipk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.fit(\n",
        "  X_train,\n",
        "  y_train,\n",
        "  epochs=10,\n",
        "  validation_split=0.2,\n",
        "  callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXR8QECMIten",
        "outputId": "2bb0137d-b75b-475f-b23e-63725999ced5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 35s 23ms/step - loss: 4.5197e-04 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9927\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 38s 26ms/step - loss: 3.8399e-04 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9926\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 37s 25ms/step - loss: 3.3273e-04 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 0.9924\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 39s 26ms/step - loss: 2.8544e-04 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9923\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 34s 23ms/step - loss: 2.4923e-04 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9923\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 37s 25ms/step - loss: 2.1775e-04 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9922\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 36s 24ms/step - loss: 1.8964e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 38s 25ms/step - loss: 1.6732e-04 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 36s 24ms/step - loss: 1.4762e-04 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9922\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 36s 24ms/step - loss: 1.3031e-04 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 0.9922\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7a55d26bd9f0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = os.path.getsize('quantized_pruned_model.tflite')\n",
        "print(f\"Model size after quantization: {model_size / 1024:.2f} KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zaTURCDIvgP",
        "outputId": "7683a35f-67b8-44f3-a31b-bd94c5d1d488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size after quantization: 242.38 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimized Model with Knowledge Distillation"
      ],
      "metadata": {
        "id": "Ii8OHpBm96h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom loss function for Knowledge Distillation\n",
        "def distillation_loss(y_true, y_pred, teacher_logits, temperature=5.0, alpha=0.5):\n",
        "    student_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "    distillation_loss = tf.keras.losses.KLDivergence()(\n",
        "        tf.nn.softmax(teacher_logits / temperature),\n",
        "        tf.nn.softmax(y_pred / temperature)\n",
        "    )\n",
        "    return alpha * student_loss + (1 - alpha) * distillation_loss\n",
        "\n",
        "# Train student model using knowledge distillation\n",
        "# student_model = create_student_model()\n",
        "# student_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "student_model = original_model\n",
        "\n",
        "# Train student model with teacher model's logits\n",
        "def train_student_model(student_model, teacher_model, X_train, y_train):\n",
        "    teacher_logits = teacher_model.predict(X_train)\n",
        "\n",
        "    # Custom training loop\n",
        "    for epoch in range(10):\n",
        "        print(f\"Epoch {epoch + 1}/10\")\n",
        "        for i in range(0, len(X_train), 32):\n",
        "            X_batch = X_train[i:i+32]\n",
        "            y_batch = y_train[i:i+32]\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_pred = student_model(X_batch, training=True)\n",
        "                loss = distillation_loss(y_batch, y_pred, teacher_logits[i:i+32])\n",
        "            grads = tape.gradient(loss, student_model.trainable_variables)\n",
        "            student_model.optimizer.apply_gradients(zip(grads, student_model.trainable_variables))\n",
        "\n",
        "# Train the student model\n",
        "train_student_model(student_model, final_model, X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmX6HqMu98rB",
        "outputId": "ed225d3d-c336-4ab7-df58-f473a16bd6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 12s 6ms/step\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate student model\n",
        "student_loss, student_accuracy = student_model.evaluate(X_test, y_test)\n",
        "print(f\"Student Model Accuracy: {student_accuracy}, Loss: {student_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNM74FvgcpeZ",
        "outputId": "ded009ee-d7bb-4512-f295-fc1719c57940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0630 - accuracy: 0.9889\n",
            "Student Model Accuracy: 0.9889000058174133, Loss: 0.0629761591553688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_save_path = 'cnn_model.h5'\n",
        "model_save_path = 'student_model.keras'\n",
        "student_model.save(model_save_path)\n",
        "\n",
        "# Get the size of the model in bytes\n",
        "model_size = os.path.getsize(model_save_path)\n",
        "print(f\"Model size: {model_size / 1024:.2f} KB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvNc6DjyBeIV",
        "outputId": "a7da896f-6769-4ec5-b1c8-9bd9406f5449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 1465.01 KB\n"
          ]
        }
      ]
    }
  ]
}